{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
  "colab": {
    "provenance": [],
    "gpuType": "T4",
    "authorship_tag": "ABX9TyMGO5M6uGfmj7OBBnwjsRQN",
    "include_colab_link": true
  },
  "kernelspec": {
    "name": "python3",
    "display_name": "Python 3"
  },
  "language_info": {
    "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
    "application/vnd.jupyter.widget-state+json": {
      "state": {}
    }
  }
},
        "d6b4e75d5b8d40c89b27968b6c486009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92557db2047548d1b15fefb88a85ab0f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f319cae0f6544c18abfb045c16292eff",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "56df44572d924ec4a1da9643d31f6832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c723404645484efa914b84fa03979c3c",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0b0d015cd254da185b8f57399004702",
            "value": 3
          }
        },
        "3faf529cdd864b7bb87e0fa5944e8ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b28c020827144d3b8ba058462dda9e1f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_53b68703fdc74a80a70708dcf50737a0",
            "value": "‚Äá3/3‚Äá[02:07&lt;00:00,‚Äá35.26s/it]"
          }
        },
        "348f86409b3145a99b1b4f2d9dd3f2eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92557db2047548d1b15fefb88a85ab0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f319cae0f6544c18abfb045c16292eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c723404645484efa914b84fa03979c3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0b0d015cd254da185b8f57399004702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b28c020827144d3b8ba058462dda9e1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53b68703fdc74a80a70708dcf50737a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "056aad5048284d84a263485c40949abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fda0bf830b143e78f2dc0ff7a82857f",
              "IPY_MODEL_d3f54abb41104df38096f2744dfdf32b",
              "IPY_MODEL_e8f66bbe211447ea88efdef421014a8c"
            ],
            "layout": "IPY_MODEL_170c5778587c4af3a5766cda511d4451"
          }
        },
        "8fda0bf830b143e78f2dc0ff7a82857f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d59dd271fea8458d8a4964f9e57be17c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1dcb14d37f8e40af97ed62fb52873ac4",
            "value": "Batches:‚Äá100%"
          }
        },
        "d3f54abb41104df38096f2744dfdf32b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_600e8a5abb6c430dbcf7e3d42cf27934",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecee435db43a440083420353ee14aa50",
            "value": 1
          }
        },
        "e8f66bbe211447ea88efdef421014a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_523939ba6af24f668cf72c07e76d2ef4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_de96af2af7a643daa0c6a957f293deae",
            "value": "‚Äá1/1‚Äá[00:00&lt;00:00,‚Äá‚Äá9.27it/s]"
          }
        },
        "170c5778587c4af3a5766cda511d4451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d59dd271fea8458d8a4964f9e57be17c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dcb14d37f8e40af97ed62fb52873ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "600e8a5abb6c430dbcf7e3d42cf27934": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecee435db43a440083420353ee14aa50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "523939ba6af24f668cf72c07e76d2ef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de96af2af7a643daa0c6a957f293deae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sama-Borhani/medical-llm-chatbot-lora-faiss-gradio/blob/main/notebook/Med_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P37O5Lg6bzn",
        "outputId": "a60d4b25-41f1-4a29-9fdb-30a6916b5fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: True\n",
            "GPU Device: Tesla T4\n",
            "CUDA Version: 12.4\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers accelerate bitsandbytes\n",
        "!pip install -q sentence-transformers faiss-cpu\n",
        "!pip install -q gradio PyPDF2 requests\n",
        "!pip install -q peft torch\n",
        "\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import requests\n",
        "import PyPDF2\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "from typing import List, Dict, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check GPU availability\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
        "print(f\"CUDA Version: {torch.version.cuda}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Authentication and Model Loading**"
      ],
      "metadata": {
        "id": "xLs3lhUDQFgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from huggingface_hub import login\n",
        "\n",
        "\n",
        "HF_TOKEN = \"\"\n",
        "login(token=HF_TOKEN)\n",
        "\n",
        "# Prepare 4-bit quantization config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "model_name = \"Writer/camel-5b-hf\"\n",
        "print(f\"Loading {model_name} with 4-bit‚Ä¶\")\n",
        "\n",
        "start_time = time.time()\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "try:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "        torch_dtype=torch.float16\n",
        "    )\n",
        "except RuntimeError as e:\n",
        "    print(f\"4-bit load failed ({e}). Retrying with 8-bit‚Ä¶\")\n",
        "    bnb_config.load_in_4bit = False\n",
        "    bnb_config.load_in_8bit = True\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "        torch_dtype=torch.float16\n",
        "    )\n",
        "\n",
        "# Ensure pad_token is set\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "loading_time = time.time() - start_time\n",
        "print(f\"Model ready in {loading_time:.2f}s\")\n",
        "print(f\"GPU Mem: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "828039ac42be45238f7cbc65671c190b",
            "d6b4e75d5b8d40c89b27968b6c486009",
            "56df44572d924ec4a1da9643d31f6832",
            "3faf529cdd864b7bb87e0fa5944e8ad7",
            "348f86409b3145a99b1b4f2d9dd3f2eb",
            "92557db2047548d1b15fefb88a85ab0f",
            "f319cae0f6544c18abfb045c16292eff",
            "c723404645484efa914b84fa03979c3c",
            "e0b0d015cd254da185b8f57399004702",
            "b28c020827144d3b8ba058462dda9e1f",
            "53b68703fdc74a80a70708dcf50737a0"
          ]
        },
        "id": "NUvWAaJHHsLR",
        "outputId": "b324991c-72e6-453d-bd9e-c722596633e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Writer/camel-5b-hf with 4-bit‚Ä¶\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "828039ac42be45238f7cbc65671c190b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model ready in 130.28s\n",
            "GPU Mem: 5.82 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Download and process PDFs**"
      ],
      "metadata": {
        "id": "TLp3Nm4xMJU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MEDICAL_PDFS = [\n",
        "    {\n",
        "        \"url\": \"https://www.who.int/publications/i/item/9789240015902\",\n",
        "        \"title\": \"WHO Guidelines for Clinical Management\",\n",
        "        \"fallback_url\": \"https://apps.who.int/iris/rest/bitstreams/1278777/retrieve\"\n",
        "    },\n",
        "    {\n",
        "        \"url\": \"https://www.cdc.gov/flu/pdf/professionals/antivirals/antiviral-summary-clinicians.pdf\",\n",
        "        \"title\": \"CDC Antiviral Guidelines\",\n",
        "        \"fallback_url\": \"https://www.cdc.gov/flu/pdf/professionals/antivirals/antiviral-summary-clinicians.pdf\"\n",
        "    },\n",
        "    {\n",
        "        \"url\": \"https://www.heart.org/-/media/files/health-topics/consumer-healthcare/what-is-cardiovascular-disease.pdf\",\n",
        "        \"title\": \"AHA Cardiovascular Disease Guide\",\n",
        "        \"fallback_url\": \"https://www.heart.org/-/media/files/health-topics/consumer-healthcare/what-is-cardiovascular-disease.pdf\"\n",
        "    }\n",
        "]\n",
        "\n",
        "def download_pdf(url: str, title: str) -> bytes:\n",
        "    \"\"\"Download PDF from URL with error handling\"\"\"\n",
        "    try:\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
        "        }\n",
        "        response = requests.get(url, headers=headers, timeout=30)\n",
        "        response.raise_for_status()\n",
        "        return response.content\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download {title}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def extract_text_from_pdf(pdf_content: bytes) -> str:\n",
        "    \"\"\"Extract text from PDF bytes\"\"\"\n",
        "    try:\n",
        "        pdf_file = BytesIO(pdf_content)\n",
        "        reader = PyPDF2.PdfReader(pdf_file)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"PDF extraction failed: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "# Sample medical text as fallback\n",
        "FALLBACK_MEDICAL_TEXT = \"\"\"\n",
        "MEDICAL KNOWLEDGE BASE - BASIC INFORMATION\n",
        "\n",
        "Cardiovascular Disease Overview:\n",
        "Cardiovascular disease (CVD) refers to conditions that involve narrowed or blocked blood vessels\n",
        "that can lead to heart attack, chest pain, or stroke. CVD is the leading cause of death globally.\n",
        "\n",
        "Common symptoms include chest pain, shortness of breath, pain in neck, jaw, throat, upper abdomen,\n",
        "or back, and pain or numbness in legs or arms.\n",
        "\n",
        "Risk factors include high blood pressure, high cholesterol, diabetes, smoking, obesity,\n",
        "physical inactivity, and family history.\n",
        "\n",
        "Treatment approaches include lifestyle modifications, medications (statins, ACE inhibitors,\n",
        "beta-blockers), and surgical interventions when necessary.\n",
        "\n",
        "Diabetes Management:\n",
        "Type 2 diabetes is a chronic condition affecting blood sugar regulation. Management involves\n",
        "blood glucose monitoring, medication adherence, dietary modifications, and regular exercise.\n",
        "\n",
        "HbA1c targets are typically below 7% for most adults. Common medications include metformin,\n",
        "sulfonylureas, and insulin therapy when needed.\n",
        "\n",
        "Respiratory Health:\n",
        "Asthma is a chronic respiratory condition characterized by airway inflammation and bronchospasm.\n",
        "Treatment includes bronchodilators, inhaled corticosteroids, and trigger avoidance.\n",
        "\n",
        "COPD (Chronic Obstructive Pulmonary Disease) management focuses on bronchodilators,\n",
        "pulmonary rehabilitation, and smoking cessation.\n",
        "\n",
        "Infectious Diseases:\n",
        "Antibiotic resistance is a growing concern. Proper antibiotic stewardship involves using\n",
        "appropriate antibiotics for confirmed bacterial infections and completing prescribed courses.\n",
        "\n",
        "Viral infections typically do not require antibiotics and are managed with supportive care.\n",
        "\n",
        "Preventive Care:\n",
        "Regular screenings include mammograms, colonoscopies, blood pressure checks, and cholesterol testing.\n",
        "Vaccinations remain crucial for disease prevention across all age groups.\n",
        "\"\"\"\n",
        "\n",
        "# Download and process PDFs\n",
        "medical_texts = []\n",
        "successful_downloads = 0\n",
        "\n",
        "print(\"Collecting medical PDF sources...\")\n",
        "\n",
        "for pdf_info in MEDICAL_PDFS:\n",
        "    print(f\"\\n Attempting to download: {pdf_info['title']}\")\n",
        "\n",
        "    # Try main URL first\n",
        "    pdf_content = download_pdf(pdf_info['url'], pdf_info['title'])\n",
        "\n",
        "    # Try fallback if main fails\n",
        "    if pdf_content is None and 'fallback_url' in pdf_info:\n",
        "        print(f\"Trying fallback URL...\")\n",
        "        pdf_content = download_pdf(pdf_info['fallback_url'], pdf_info['title'])\n",
        "\n",
        "    if pdf_content:\n",
        "        text = extract_text_from_pdf(pdf_content)\n",
        "        if text and len(text.strip()) > 100:  # Minimum text threshold\n",
        "            medical_texts.append({\n",
        "                'title': pdf_info['title'],\n",
        "                'content': text,\n",
        "                'source': pdf_info['url']\n",
        "            })\n",
        "            successful_downloads += 1\n",
        "            print(f\"Successfully processed: {pdf_info['title']} ({len(text)} characters)\")\n",
        "        else:\n",
        "            print(f\"Insufficient text extracted from {pdf_info['title']}\")\n",
        "    else:\n",
        "        print(f\"Failed to download {pdf_info['title']}\")\n",
        "\n",
        "# Add fallback medical text if no PDFs were successfully downloaded\n",
        "if successful_downloads == 0:\n",
        "    print(\"\\n No PDFs downloaded successfully. Using fallback medical knowledge base.\")\n",
        "    medical_texts.append({\n",
        "        'title': 'Fallback Medical Knowledge Base',\n",
        "        'content': FALLBACK_MEDICAL_TEXT,\n",
        "        'source': 'Built-in medical knowledge'\n",
        "    })\n",
        "    successful_downloads = 1\n",
        "\n",
        "print(f\"\\n Total medical sources collected: {len(medical_texts)}\")\n",
        "total_chars = sum(len(text['content']) for text in medical_texts)\n",
        "print(f\" Total text characters: {total_chars:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asukkhxALYYh",
        "outputId": "6aeaaed4-1b4a-4368-dd94-f08476bf269d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medical PDF sources...\n",
            "\n",
            " Attempting to download: WHO Guidelines for Clinical Management\n",
            "Failed to download WHO Guidelines for Clinical Management: 404 Client Error: not found for url: https://www.who.int/publications/i/item/9789240015902\n",
            "Trying fallback URL...\n",
            "Failed to download WHO Guidelines for Clinical Management: 403 Client Error: Forbidden for url: https://iris.who.int/rest/bitstreams/1278777/retrieve\n",
            "Failed to download WHO Guidelines for Clinical Management\n",
            "\n",
            " Attempting to download: CDC Antiviral Guidelines\n",
            "Failed to download CDC Antiviral Guidelines: 404 Client Error: Not Found for url: https://www.cdc.gov/flu/pdf/professionals/antivirals/antiviral-summary-clinicians.pdf\n",
            "Trying fallback URL...\n",
            "Failed to download CDC Antiviral Guidelines: 404 Client Error: Not Found for url: https://www.cdc.gov/flu/pdf/professionals/antivirals/antiviral-summary-clinicians.pdf\n",
            "Failed to download CDC Antiviral Guidelines\n",
            "\n",
            " Attempting to download: AHA Cardiovascular Disease Guide\n",
            "PDF extraction failed: EOF marker not found\n",
            "Insufficient text extracted from AHA Cardiovascular Disease Guide\n",
            "\n",
            " No PDFs downloaded successfully. Using fallback medical knowledge base.\n",
            "\n",
            " Total medical sources collected: 1\n",
            " Total text characters: 1,879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RAG System Setup with FAISS**"
      ],
      "metadata": {
        "id": "6uxuQQLpL5D1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "from transformers import AutoTokenizer as CE_Tok, AutoModelForSequenceClassification as CE_Mod\n",
        "\n",
        "# 1. Regex sentence splitter\n",
        "def chunk_text_semantic(text: str, max_tokens: int = 200):\n",
        "    # Split on end-of-sentence punctuation\n",
        "    sentences = re.split(r'(?<=[\\.!?])\\s+', text)\n",
        "    chunks, current = [], []\n",
        "    for s in sentences:\n",
        "        candidate = \" \".join(current + [s])\n",
        "        if len(candidate.split()) <= max_tokens:\n",
        "            current.append(s)\n",
        "        else:\n",
        "            if current:\n",
        "                chunks.append(\" \".join(current))\n",
        "            current = [s]\n",
        "    if current:\n",
        "        chunks.append(\" \".join(current))\n",
        "    return chunks\n",
        "\n",
        "# 2. Rebuilding semantic chunks & metadata\n",
        "print(\"\\n Processing medical texts into semantic chunks...\")\n",
        "all_chunks, chunk_metadata = [], []\n",
        "for doc in medical_texts:\n",
        "    sem_chunks = chunk_text_semantic(doc['content'])\n",
        "    for i, chunk in enumerate(sem_chunks):\n",
        "        all_chunks.append(chunk)\n",
        "        chunk_metadata.append({\n",
        "            'title': doc['title'],\n",
        "            'source': doc['source'],\n",
        "            'chunk_id': i\n",
        "        })\n",
        "print(f\" Total semantic chunks: {len(all_chunks)}\")\n",
        "\n",
        "# 3. Embeddings & FAISS index\n",
        "print(\"Creating embeddings...\")\n",
        "embeddings = embedding_model.encode(all_chunks, show_progress_bar=True)\n",
        "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
        "index.add(embeddings.astype('float32'))\n",
        "print(f\"FAISS index with {index.ntotal} vectors\")\n",
        "\n",
        "# 4. Cross-encoder for reranking\n",
        "ce_tokenizer = CE_Tok.from_pretrained(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "ce_model     = CE_Mod.from_pretrained(\"cross-encoder/ms-marco-MiniLM-L-6-v2\").to(model.device)\n",
        "\n",
        "def rerank_candidates(query: str, cands: list, top_k: int = 3):\n",
        "    pairs = [(query, c['chunk']) for c in cands]\n",
        "    inputs = ce_tokenizer(pairs, return_tensors='pt', truncation=True, padding=True).to(model.device)\n",
        "    scores = ce_model(**inputs).logits.squeeze(-1).tolist()\n",
        "    ranked = sorted(zip(cands, scores), key=lambda x: x[1], reverse=True)\n",
        "    return [c for c,_ in ranked[:top_k]]\n",
        "\n",
        "def retrieve_relevant_chunks(query: str, base_k: int = 10):\n",
        "    # initial FAISS retrieval\n",
        "    q_emb = embedding_model.encode([query])\n",
        "    scores, idxs = index.search(q_emb.astype('float32'), base_k)\n",
        "    cands = []\n",
        "    for score, idx in zip(scores[0], idxs[0]):\n",
        "        if score >= 0.1:\n",
        "            cands.append({\n",
        "                'chunk': all_chunks[idx],\n",
        "                'metadata': chunk_metadata[idx],\n",
        "                'score': float(score)\n",
        "            })\n",
        "    # rerank top candidates\n",
        "    top = rerank_candidates(query, cands, top_k=3)\n",
        "    if not top:\n",
        "        top = [{\n",
        "            'chunk': FALLBACK_MEDICAL_TEXT,\n",
        "            'metadata': {'title':'Fallback Knowledge Base','source':'builtin'},\n",
        "            'score': 1.0\n",
        "        }]\n",
        "    return top"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "056aad5048284d84a263485c40949abf",
            "8fda0bf830b143e78f2dc0ff7a82857f",
            "d3f54abb41104df38096f2744dfdf32b",
            "e8f66bbe211447ea88efdef421014a8c",
            "170c5778587c4af3a5766cda511d4451",
            "d59dd271fea8458d8a4964f9e57be17c",
            "1dcb14d37f8e40af97ed62fb52873ac4",
            "600e8a5abb6c430dbcf7e3d42cf27934",
            "ecee435db43a440083420353ee14aa50",
            "523939ba6af24f668cf72c07e76d2ef4",
            "de96af2af7a643daa0c6a957f293deae"
          ]
        },
        "id": "S7ntIT2QLyXd",
        "outputId": "5bf1dfd3-9ee8-4c06-b821-78a0cf58a48b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Processing medical texts into semantic chunks...\n",
            " Total semantic chunks: 2\n",
            "Creating embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "056aad5048284d84a263485c40949abf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index with 2 vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Medical Chatbot with RAG Integration**"
      ],
      "metadata": {
        "id": "ewnuAGeDMXRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jinja2 import Template\n",
        "\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "You are a medical researcher providing evidence-based answers.\n",
        "\n",
        "Context:\n",
        "{% for src in sources %}\n",
        "- {{src.metadata.title}}: ‚Äú{{src.chunk[:150]}}‚Ä¶‚Äù (score: {{src.score:.2f}})\n",
        "{% endfor %}\n",
        "\n",
        "Question: {{question}}\n",
        "\n",
        "Please answer in this format:\n",
        "1. **Summary** (2-3 sentences)\n",
        "2. **Detailed Explanation** (bullet points)\n",
        "3. **References** (list source titles)\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "def generate_medical_response(query: str, history: list):\n",
        "    # 1) Short-term memory\n",
        "    mem = \"\".join(f\"User: {q}\\nAssistant: {a}\\n\" for q,a in history[-3:])\n",
        "    # 2) Retrieval & structural prompt\n",
        "    chunks = retrieve_relevant_chunks(query)\n",
        "    prompt_body = Template(PROMPT_TEMPLATE).render(sources=chunks, question=query)\n",
        "    full_prompt = mem + prompt_body\n",
        "\n",
        "    # 3) Outline pass\n",
        "    inputs = tokenizer(full_prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(model.device)\n",
        "    outline_ids = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=100,\n",
        "        temperature=0.3,\n",
        "        top_k=50,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=1.2,\n",
        "        no_repeat_ngram_size=3,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    outline = tokenizer.decode(outline_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # 4) Expansion pass\n",
        "    exp_prompt = full_prompt + \"\\n\\nOutline:\\n\" + outline + \"\\n\\nFull Answer:\"\n",
        "    inputs2 = tokenizer(exp_prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(model.device)\n",
        "    out_ids = model.generate(\n",
        "        **inputs2,\n",
        "        max_new_tokens=200,\n",
        "        temperature=0.3,\n",
        "        top_k=50,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=1.2,\n",
        "        no_repeat_ngram_size=3,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    answer = tokenizer.decode(out_ids[0], skip_special_tokens=True).strip()\n",
        "    return answer, chunks\n"
      ],
      "metadata": {
        "id": "DUkYGW5vMbe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gradio Interface**"
      ],
      "metadata": {
        "id": "3SkaNfdJMwwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def chatbot_interface(message: str, history: list) -> tuple:\n",
        "    # Add medical disclaimer if not present\n",
        "    disclaimer = \"\"\n",
        "    if \"medical advice\" not in message.lower():\n",
        "        disclaimer = \"\\n\\n‚ö†Ô∏è **Medical Disclaimer**: This information is for educational purposes only. Please consult with healthcare professionals for medical advice.\"\n",
        "\n",
        "    try:\n",
        "        # Generate response with RAG (must accept history if your backend uses memory)\n",
        "        response, sources = generate_medical_response(message, history)\n",
        "        # Add source citations\n",
        "        source_info = \"\\n\\n **Sources consulted:**\\n\"\n",
        "        for i, source in enumerate(sources[:2], 1):  # Top 2 sources\n",
        "            source_info += f\"{i}. {source['metadata']['title']} (Score: {source['score']:.3f})\\n\"\n",
        "        full_response = response + disclaimer + source_info\n",
        "        # Update history\n",
        "        history.append([message, full_response])\n",
        "        return history, \"\"\n",
        "    except Exception as e:\n",
        "        error_response = f\"Sorry, I encountered an error: {str(e)}\\n\\nPlease try rephrasing your question.\"\n",
        "        history.append([message, error_response])\n",
        "        return history, \"\"\n",
        "\n",
        "print(\" Launching Gradio interface...\")\n",
        "\n",
        "with gr.Blocks() as iface:\n",
        "    gr.Markdown(\"# ü©∫ Medical Chatbot with RAG\")\n",
        "    gr.Markdown(\"*Powered by Camel-5B and medical knowledge retrieval*\")\n",
        "\n",
        "    chatbot = gr.Chatbot(height=400)\n",
        "\n",
        "    with gr.Row():\n",
        "        msg = gr.Textbox(\n",
        "            label=\"Ask a medical question\",\n",
        "            placeholder=\"e.g., What are the symptoms of diabetes?\",\n",
        "            lines=2\n",
        "        )\n",
        "        send_btn = gr.Button(\"Send\")\n",
        "    clear = gr.Button(\"Clear Conversation\")\n",
        "\n",
        "    # Setup event handlers\n",
        "    def respond_and_clear(message, history):\n",
        "        return chatbot_interface(message, history)\n",
        "\n",
        "    send_btn.click(respond_and_clear, [msg, chatbot], [chatbot, msg])\n",
        "    msg.submit(respond_and_clear, [msg, chatbot], [chatbot, msg])\n",
        "    clear.click(lambda: [], None, chatbot)\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            \"What are the symptoms of cardiovascular disease?\",\n",
        "            \"How is diabetes managed?\",\n",
        "            \"What are the risk factors for heart disease?\",\n",
        "            \"Explain asthma treatment options\",\n",
        "            \"What preventive care screenings are recommended?\"\n",
        "        ],\n",
        "        inputs=msg\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "    gr.Markdown(f\"**System Info:** {len(medical_texts)} medical sources ‚Ä¢ {len(all_chunks)} knowledge chunks ‚Ä¢ FAISS vector search\")\n",
        "\n",
        "iface.launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "l55Yn1pjMzRL",
        "outputId": "13a8d40b-bf08-456d-9c3f-c136c792df41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Launching Gradio interface...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://c0606a5ef83785f5c0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c0606a5ef83785f5c0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7862 <> https://c0606a5ef83785f5c0.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}
